{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples and Exercises from Think Stats, 2nd Edition\n",
    "\n",
    "http://thinkstats2.com\n",
    "\n",
    "Copyright 2016 Allen B. Downey\n",
    "\n",
    "MIT License: https://opensource.org/licenses/MIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import thinkstats2\n",
    "import thinkplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares\n",
    "\n",
    "One more time, let's load up the NSFG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import first\n",
    "live, firsts, others = first.MakeFrames()\n",
    "live = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "ages = live.agepreg\n",
    "weights = live.totalwgt_lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function computes the intercept and slope of the least squares fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from thinkstats2 import Mean, MeanVar, Var, Std, Cov\n",
    "\n",
    "def LeastSquares(xs, ys):\n",
    "    meanx, varx = MeanVar(xs)\n",
    "    meany = Mean(ys)\n",
    "\n",
    "    slope = Cov(xs, ys, meanx, meany) / varx\n",
    "    inter = meany - slope * meanx\n",
    "\n",
    "    return inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's the least squares fit to birth weight as a function of mother's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inter, slope = LeastSquares(ages, weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The intercept is often easier to interpret if we evaluate it at the mean of the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inter + slope * 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And the slope is easier to interpret if we express it in pounds per decade (or ounces per year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "slope * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function evaluates the fitted line at the given `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def FitLine(xs, inter, slope):\n",
    "    fit_xs = np.sort(xs)\n",
    "    fit_ys = inter + slope * fit_xs\n",
    "    return fit_xs, fit_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fit_xs, fit_ys = FitLine(ages, inter, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's a scatterplot of the data with the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# this turned out pretty nice I felt that the line that it found seemed reasonable and would represent the data well.\n",
    "thinkplot.Scatter(ages, weights, color='blue', alpha=0.1, s=10)\n",
    "thinkplot.Plot(fit_xs, fit_ys, color='white', linewidth=3)\n",
    "thinkplot.Plot(fit_xs, fit_ys, color='red', linewidth=2)\n",
    "thinkplot.Config(xlabel=\"Mother's age (years)\",\n",
    "                 ylabel='Birth weight (lbs)',\n",
    "                 axis=[10, 45, 0, 15],\n",
    "                 legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Residuals\n",
    "\n",
    "The following functon computes the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def Residuals(xs, ys, inter, slope):\n",
    "    xs = np.asarray(xs)\n",
    "    ys = np.asarray(ys)\n",
    "    res = ys - (inter + slope * xs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we can add the residuals as a column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "live['residual'] = Residuals(ages, weights, inter, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To visualize the residuals, I'll split the respondents into groups by age, then plot the percentiles of the residuals versus the average age in each group.\n",
    "\n",
    "First I'll make the groups and compute the average age in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "bins = np.arange(10, 48, 3)\n",
    "indices = np.digitize(live.agepreg, bins)\n",
    "groups = live.groupby(indices)\n",
    "\n",
    "age_means = [group.agepreg.mean() for _, group in groups][1:-1]\n",
    "age_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Next I'll compute the CDF of the residuals in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cdfs = [thinkstats2.Cdf(group.residual) for _, group in groups][1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function plots percentiles of the residuals against the average age in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def PlotPercentiles(age_means, cdfs):\n",
    "    thinkplot.PrePlot(3)\n",
    "    for percent in [75, 50, 25]:\n",
    "        weight_percentiles = [cdf.Percentile(percent) for cdf in cdfs]\n",
    "        label = '%dth' % percent\n",
    "        thinkplot.Plot(age_means, weight_percentiles, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the 25th, 50th, and 75th percentiles.\n",
    "\n",
    "Curvature in the residuals suggests a non-linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "PlotPercentiles(age_means, cdfs)\n",
    "\n",
    "thinkplot.Config(xlabel=\"Mother's age (years)\",\n",
    "                 ylabel='Residual (lbs)',\n",
    "                 xlim=[10, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sampling distribution\n",
    "\n",
    "To estimate the sampling distribution of `inter` and `slope`, I'll use resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def SampleRows(df, nrows, replace=False):\n",
    "    \"\"\"Choose a sample of rows from a DataFrame.\n",
    "\n",
    "    df: DataFrame\n",
    "    nrows: number of rows\n",
    "    replace: whether to sample with replacement\n",
    "\n",
    "    returns: DataDf\n",
    "    \"\"\"\n",
    "    indices = np.random.choice(df.index, nrows, replace=replace)\n",
    "    sample = df.loc[indices]\n",
    "    return sample\n",
    "\n",
    "def ResampleRows(df):\n",
    "    \"\"\"Resamples rows from a DataFrame.\n",
    "\n",
    "    df: DataFrame\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    return SampleRows(df, len(df), replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function resamples the given dataframe and returns lists of estimates for `inter` and `slope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def SamplingDistributions(live, iters=101):\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        sample = ResampleRows(live)\n",
    "        ages = sample.agepreg\n",
    "        weights = sample.totalwgt_lb\n",
    "        estimates = LeastSquares(ages, weights)\n",
    "        t.append(estimates)\n",
    "\n",
    "    inters, slopes = zip(*t)\n",
    "    return inters, slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inters, slopes = SamplingDistributions(live, iters=1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following function takes a list of estimates and prints the mean, standard error, and 90% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def Summarize(estimates, actual=None):\n",
    "    mean = Mean(estimates)\n",
    "    stderr = Std(estimates, mu=actual)\n",
    "    cdf = thinkstats2.Cdf(estimates)\n",
    "    ci = cdf.ConfidenceInterval(90)\n",
    "    print('mean, SE, CI', mean, stderr, ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's  the summary for `inter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Summarize(inters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And for `slope`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Summarize(slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise:** Use `ResampleRows` and generate a list of estimates for the mean birth weight.  Use `Summarize` to compute the SE and CI for these estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## So one of the main ideas in the central limit theorem is that if we take many samples.\n",
    "## Eventually we will be able to determine important things about the population.\n",
    "## Here we are only doing 1000 itterations but we are looking for the mean over and overagain.\n",
    "## This gives us insight into what the population mean actually is without having all of the information\n",
    "## about the population itself.\n",
    "iters = 1000\n",
    "estimates = [ResampleRows(live).totalwgt_lb.mean()\n",
    "             for _ in range(iters)]\n",
    "Summarize(estimates)\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualizing uncertainty\n",
    "\n",
    "To show the uncertainty of the estimated slope and intercept, we can generate a fitted line for each resampled estimate and plot them on top of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## For this one we are taking our samples that we took and building lines based on the samples mean and y intercept.\n",
    "## The problem is there are an infinite number of possibilities for how we would draw the line of best fit.\n",
    "## If we choose poorly then we wont make accurate predictions when we try to interpolate data within the domain of x or\n",
    "## extrapolate data outside of the sample domain of x.\n",
    "## The goal is to accurately predict the values y.\n",
    "## By taking many iterations we can find averages based on what we learned from manny samples.\n",
    "for slope, inter in zip(slopes, inters):\n",
    "    fxs, fys = FitLine(age_means, inter, slope)\n",
    "    thinkplot.Plot(fxs, fys, color='gray', alpha=0.01)\n",
    "    \n",
    "thinkplot.Config(xlabel=\"Mother's age (years)\",\n",
    "                 ylabel='Residual (lbs)',\n",
    "                 xlim=[10, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Or we can make a neater (and more efficient plot) by computing fitted lines and finding percentiles of the fits for each value of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def PlotConfidenceIntervals(xs, inters, slopes, percent=90, **options):\n",
    "    fys_seq = []\n",
    "    for inter, slope in zip(inters, slopes):\n",
    "        fxs, fys = FitLine(xs, inter, slope)\n",
    "        fys_seq.append(fys)\n",
    "\n",
    "    p = (100 - percent) / 2\n",
    "    percents = p, 100 - p\n",
    "    low, high = thinkstats2.PercentileRows(fys_seq, percents)\n",
    "    thinkplot.FillBetween(fxs, low, high, **options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This example shows the confidence interval for the fitted values at each mother's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "PlotConfidenceIntervals(age_means, inters, slopes, percent=90, \n",
    "                        color='gray', alpha=0.3, label='90% CI')\n",
    "PlotConfidenceIntervals(age_means, inters, slopes, percent=50,\n",
    "                        color='gray', alpha=0.5, label='50% CI')\n",
    "\n",
    "thinkplot.Config(xlabel=\"Mother's age (years)\",\n",
    "                 ylabel='Residual (lbs)',\n",
    "                 xlim=[10, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Coefficient of determination\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient compares the variance of the residuals to the variance of the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def CoefDetermination(ys, res):\n",
    "    return 1 - Var(res) / Var(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For birth weight and mother's age $R^2$ is very small, indicating that the mother's age predicts a small part of the variance in birth weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inter, slope = LeastSquares(ages, weights)\n",
    "res = Residuals(ages, weights, inter, slope)\n",
    "r2 = CoefDetermination(weights, res)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can confirm that $R^2 = \\rho^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('rho', thinkstats2.Corr(ages, weights))\n",
    "print('R', np.sqrt(r2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To express predictive power, I think it's useful to compare the standard deviation of the residuals to the standard deviation of the dependent variable, as a measure RMSE if you try to guess birth weight with and without taking into account mother's age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Std(ys)', Std(weights))\n",
    "print('Std(res)', Std(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As another example of the same idea, here's how much we can improve guesses about IQ if we know someone's SAT scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "var_ys = 15**2\n",
    "rho = 0.72\n",
    "r2 = rho**2\n",
    "var_res = (1 - r2) * var_ys\n",
    "std_res = np.sqrt(var_res)\n",
    "std_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Hypothesis testing with slopes\n",
    "\n",
    "Here's a `HypothesisTest` that uses permutation to test whether the observed slope is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class SlopeTest(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        ages, weights = data\n",
    "        _, slope = thinkstats2.LeastSquares(ages, weights)\n",
    "        return slope\n",
    "\n",
    "    def MakeModel(self):\n",
    "        _, weights = self.data\n",
    "        self.ybar = weights.mean()\n",
    "        self.res = weights - self.ybar\n",
    "\n",
    "    def RunModel(self):\n",
    "        ages, _ = self.data\n",
    "        weights = self.ybar + np.random.permutation(self.res)\n",
    "        return ages, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ht = SlopeTest((ages, weights))\n",
    "pvalue = ht.PValue()\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Under the null hypothesis, the largest slope we observe after 1000 tries is substantially less than the observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ht.actual, ht.MaxTestStat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also use resampling to estimate the sampling distribution of the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sampling_cdf = thinkstats2.Cdf(slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The distribution of slopes under the null hypothesis, and the sampling distribution of the slope under resampling, have the same shape, but one has mean at 0 and the other has mean at the observed slope.\n",
    "\n",
    "To compute a p-value, we can count how often the estimated slope under the null hypothesis exceeds the observed slope, or how often the estimated slope under resampling falls below 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# there is a clear difference in means here even though they are small.\n",
    "# This seems to coincide with the fact that the confidence intervals did not overlap.\n",
    "thinkplot.PrePlot(2)\n",
    "thinkplot.Plot([0, 0], [0, 1], color='0.8')\n",
    "ht.PlotCdf(label='null hypothesis')\n",
    "\n",
    "thinkplot.Cdf(sampling_cdf, label='sampling distribution')\n",
    "\n",
    "thinkplot.Config(xlabel='slope (lbs / year)',\n",
    "                   ylabel='CDF',\n",
    "                   xlim=[-0.03, 0.03],\n",
    "                   legend=True, loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here's how to get a p-value from the sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Pvalue of zero is significant.\n",
    "pvalue = sampling_cdf[0]\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Resampling with weights\n",
    "\n",
    "Resampling provides a convenient way to take into account the sampling weights associated with respondents in a stratified survey design.\n",
    "\n",
    "The following function resamples rows with probabilities proportional to weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def ResampleRowsWeighted(df, column='finalwgt'):\n",
    "    weights = df[column]\n",
    "    cdf = thinkstats2.Cdf(dict(weights))\n",
    "    indices = cdf.Sample(len(weights))\n",
    "    sample = df.loc[indices]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it to estimate the mean birthweight and compute SE and CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "iters = 100\n",
    "estimates = [ResampleRowsWeighted(live).totalwgt_lb.mean()\n",
    "             for _ in range(iters)]\n",
    "Summarize(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And here's what the same calculation looks like if we ignore the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimates = [thinkstats2.ResampleRows(live).totalwgt_lb.mean()\n",
    "             for _ in range(iters)]\n",
    "Summarize(estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The difference is non-negligible, which suggests that there are differences in birth weight between the strata in the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "**Exercise:** Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height. How would you best present the estimated parameters for a model like this where one of the variables is log-transformed? If you were trying to guess someoneâ€™s weight, how much would it help to know their height?\n",
    "\n",
    "Like the NSFG, the BRFSS oversamples some groups and provides a sampling weight for each respondent. In the BRFSS data, the variable name for these weights is totalwt. Use resampling, with and without weights, to estimate the mean height of respondents in the BRFSS, the standard error of the mean, and a 90% confidence interval. How much does correct weighting affect the estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the BRFSS data and extract heights and log weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import brfss\n",
    "\n",
    "df = brfss.ReadBrfss(nrows=None)\n",
    "df = df.dropna(subset=['htm3', 'wtkg2'])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate intercept and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We need to build the y intercept and the slope based on logarithmic weights.\n",
    "# Thinkstats2.LeastSquarers returns first the y intercept then returns the slope.\n",
    "inter, slope = thinkstats2.LeastSquares(heights, log_weights)\n",
    "print(\"Our y-intercept: {}\".format(inter))\n",
    "\n",
    "# Interesting so we are seeing a much smaller gradual slope here. That is because the log function smoothes it out.\n",
    "print(\"the slope m: {}\".format(slope))\n",
    "\n",
    "# Solution goes here\n",
    "# So our line of best fit starts at about 1 and then increases by .005 for each unit of height. (Based on a logarithmic scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a scatter plot of the data and show the fitted line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# This one is different from the one below.\n",
    "# The plot below this undoes the log function to give back the values.\n",
    "# That is why it is called the inverse.\n",
    "# Log functions can help us normalize the data when it is skewed. (In this case that was the goal)\n",
    "# This is why we are now getting a straight line.\n",
    "# The data has been altered by the log function.\n",
    "# Bet if we plotted the histogram it would have been skewed and now we can make predictions as if the data was normal.\n",
    "# But we need to be able to get back to the original results so we can talk about them.\n",
    "# People have trouble thinking in terms of powers.\n",
    "thinkplot.Scatter(heights, log_weights, alpha=0.01, s=5)\n",
    "fxs, fys = thinkstats2.FitLine(heights, inter, slope)\n",
    "thinkplot.Plot(fxs, fys, color='red')\n",
    "thinkplot.Config(xlabel='Height (cm)', ylabel='log10 weight (kg)', legend=False)\n",
    "\n",
    "\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the same plot but apply the inverse transform to show weights on a linear (not log) scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now we are looking back at our heights and weights (The original ones from the dataframe.)\n",
    "# Alpha makes the chart see through I think.\n",
    "# I need to figure out what s means. This could be the sample standard deviation but its a bit odd to be exactly 5.\n",
    "# Usually we have a setup for the plots saying how many items we are going to put on our graph.\n",
    "thinkplot.Scatter(heights, weights, alpha=0.01, s=5)\n",
    "fxs, fys = thinkstats2.FitLine(heights, inter, slope)\n",
    "# this part is important remember fys was built using the log function.\n",
    "# Logs are returning the power that is why we are plotting by raising to the power of y.\n",
    "# Raising 10 to the power of fys is the inverse since fys is the log values. So i assume this puts it in base 10 values.\n",
    "# Our nomral number system.\n",
    "# oh cool so before we made it linear and normalized. This gave us our line.\n",
    "# when we are using it to make predicions we put it back into a base 10 system.\n",
    "# That is why it now curves to look like a exponential graph.\n",
    "thinkplot.Plot(fxs, 10**fys, color='red')\n",
    "thinkplot.Config(xlabel='Height (cm)', ylabel='Weight (kg)', legend=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot percentiles of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# again we go back to looking at residuals.\n",
    "# what we are trying to do here is see what the difference vertically our values differ from the line we created and our observed values.\n",
    "res = thinkstats2.Residuals(heights, log_weights, inter, slope)\n",
    "df['residual'] = res\n",
    "\n",
    "# our setup we want to include the extents of the graph so 130 is the min and 210 is the max x values.\n",
    "# We also define the increments our graph goes up by.\n",
    "bins = np.arange(130, 210, 5)\n",
    "\n",
    "# This function sorts our data into bins based on their index.\n",
    "indices = np.digitize(df.htm3, bins)\n",
    "groups = df.groupby(indices)\n",
    "\n",
    "# This groups up our means from our various samples.\n",
    "means = [group.htm3.mean() for i, group in groups][1:-1]\n",
    "\n",
    "# builds our cdf values based on the groups we have\n",
    "cdfs = [thinkstats2.Cdf(group.residual) for i, group in groups][1:-1]\n",
    "\n",
    "# We will have three items to print on this graph.\n",
    "# We want to look at 75 50 25. I think that is because those values translate to\n",
    "# Quartile Q1 is 25% of our data, Q2 is the middle mean 50% of our data,\n",
    "# Quartile Q3 is 75% of our data. We want to see if the weighted residuals follow a linear path.\n",
    "# We are looking for straight parallel lines if they are straight then the differences between\n",
    "# observed and actual values are linear if they are parallel that means that the varience is the same\n",
    "# between the different quantiles of data.\n",
    "thinkplot.PrePlot(3)\n",
    "for percent in [75, 50, 25]:\n",
    "    ys = [cdf.Percentile(percent) for cdf in cdfs]\n",
    "    label = '%dth' % percent\n",
    "    thinkplot.Plot(means, ys, label=label)\n",
    "\n",
    "thinkplot.Config(xlabel='height (cm)', ylabel='residual weight (kg)', legend=False)\n",
    "\n",
    "# So we are seeing that overall our data is not linear.\n",
    "# The data is pretty linear within a certain range of heights.\n",
    "# I would say it starts being linear for the top two around about 145 cm then they all follow eachother at about 150 cm.\n",
    "# This trend goes until about 190 cm.\n",
    "# So I would feel pretty comfortable making interpolated predictions within the range of 150 cm to 190.\n",
    "# Also the lines seem to remain parallel within that range with the bottom line being a bit more hard to predict.\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# I believe rho is that curly p value I was talking to Joseph about on the forums.\n",
    "# Can you check to make sure I was explaining it correctly to him?\n",
    "rho = thinkstats2.Corr(heights, log_weights)\n",
    "rho\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute coefficient of determination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# rho and r squared should be the same if everything worked as planned.\n",
    "# Best of all I believe that rho represents the population.\n",
    "# This is important because we rarely have info on the population data.\n",
    "# If all assumptions have been followed that means that given these values we can start to make predictions.\n",
    "r2 = thinkstats2.CoefDetermination(log_weights, res)\n",
    "r2\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that $R^2 = \\rho^2$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# my expectation is that this will be very close to zero.\n",
    "# So it is zero which means we now have information about the variance of the population.\n",
    "# I feel that the reason everthing works out so nicely here is because we took several samples and found the\n",
    "# y intercepts and slopes by averaging the results within each of the samples we took.\n",
    "# Now we are confident that we have a representative sample.\n",
    "# I am however concerned that r squared is only at 28% so that means that other factors are involved\n",
    "# when calculating the babys weight. The height only explains 28% of the variance.\n",
    "rho**2 - r2\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Std(ys), which is the RMSE of predictions that don't use height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# So now we need everything to be in the same unit so we standardize them.\n",
    "# I think this means we are dividing by standard deviation so they become standard deviation units.\n",
    "std_ys = thinkstats2.Std(log_weights)\n",
    "std_ys\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Std(res), the RMSE of predictions that do use height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# We want the root mean square error.\n",
    "# our goal is to find out how concentrated the values are around our line.\n",
    "# Lower numbers means the values are more concentrated around the line.\n",
    "# We saw in the graph before that there was some distance between observed values and the line.\n",
    "# So I am expecting less than perfect results.\n",
    "std_res = thinkstats2.Std(res)\n",
    "std_res\n",
    "# Cool this was actually quite a bit lower than I expected.\n",
    "# Low is good it means that our data is concentrated pretty well around the line we created.\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much does height information reduce RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# hmm this is interesting we are doing more than meets the eye on this formula.\n",
    "# This will be a probability value between 0 and 1 where we are looking at the values above the point we are interested in.\n",
    "# Also I think we are actually removing the standardization here.\n",
    "# Remember we created std_res and std_ys by dividing by standard deviation.\n",
    "# I think this means we are divding two fractions both of wich have the standard deviation variable as its denominator.\n",
    "# One copy dot flip later those values would cancel themselves out. This means its litterally impossible to get a value\n",
    "# out side of the range 0 and 1 for this formula.\n",
    "\n",
    "1- std_res/std_ys\n",
    "\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use resampling to compute sampling distributions for inter and slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Here we go again we are going to take more samples\n",
    "t = []\n",
    "for _ in range(100):\n",
    "    sample = thinkstats2.ResampleRows(df)\n",
    "    estimates = thinkstats2.LeastSquares(sample.htm3, np.log10(sample.wtkg2))\n",
    "    t.append(estimates)\n",
    "\n",
    "# interesting I did not know what the zip function did.\n",
    "# apparently it groups items as tuples. I think this is so we can compare our results from before.\n",
    "# So its appending the new samples to the old ones found in inters and slopes.\n",
    "# I bet this means we will be graphing the differences to see how they stack up.\n",
    "inters, slopes = zip(*t)\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the sampling distribution of slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# It looks a little bit like a sigmoid function. Wish it was a bit smoother. Maybe its because the confidence interval is so small.\n",
    "# Otherwise it looks pretty good.\n",
    "cdf = thinkstats2.Cdf(slopes)\n",
    "thinkplot.Cdf(cdf)\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the p-value of the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# My IDE has been frozen for this entire assignment so I hope my predictions are correct.\n",
    "# I suspect we will get a p-value showing significant results here. Something close to zero.\n",
    "pvalue = cdf[0]\n",
    "pvalue\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the 90% confidence interval of slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# I almost made a mistake here in logic. Similar to the mistake where people look for Percentile(90) thinking that they\n",
    "# have captured 90% of the data. But the data that I am looking for starts at the 95% mark and omits the bottom 5% capturing 90% of the data between those points.\n",
    "ci = cdf.Percentile(5), cdf.Percentile(95)\n",
    "ci\n",
    "# That is a much tighter range than I expected. Thats kind of insane so now we have a very strong indicator that 90%\n",
    "# of the time we would have captured our slope. So this means we are very confident that we have chosen a good value for our slope.\n",
    "# If we choose the average it should fall within this confidence interval.\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean of the sampling distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "mean = thinkstats2.Mean(slopes)\n",
    "mean\n",
    "# nice as expected our confidence interval was at 0.0052662 and .0053017\n",
    "# Lower confidence 0.0052662 our mean is between at .005283 with our upper confidence at .0053017\n",
    "# Bam we captured it.\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the standard deviation of the sampling distribution, which is the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# I am expecting this to be pretty small because it would be contained within the confidence intervals we discovered before.\n",
    "# 1 standard deviation from the mean would hold about 68% of the values two standard deviations would hold about 95% three are 99.7% I think.\n",
    "stderr = thinkstats2.Std(slopes)\n",
    "stderr\n",
    "# as expected a very small value. Woot! I am getting this. :)\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample rows without weights, compute mean height, and summarize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Now we are about to do hypothesis testing. We are trying to assume that the mean represented in our origional results\n",
    "# is in fact true and then by contradiction find that it is in fact different.\n",
    "estimates_unweighted = [thinkstats2.ResampleRows(df).htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_unweighted)\n",
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample rows with weights.  Note that the weight column in this dataset is called `finalwt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "estimates_weighted = [ResampleRowsWeighted(df, 'finalwt').htm3.mean() for _ in range(100)]\n",
    "Summarize(estimates_weighted)\n",
    "# Solution goes here\n",
    "# Awesome in both cases we have captured the mean within the CI\n",
    "# I also am showing that the original CI range is outside of the weighted CI range.\n",
    "# Which means that the mean lives in a different location then we had origionaly thought.\n",
    "# This feels like there is sufficient evidence to reject the null hypothesis in favor of the calculated one based on the CI.\n",
    "# We had a pvalue to support this idea.\n",
    "# I am concerned about r squared though it only showed that the variation between our independent and dependant variables at around 28%.\n",
    "# My IDE keeps freezing so I cant see the value for r-squared but I remember it being too low for my comfort level.\n",
    "# Im going to go out on a ledge here and say something contrary to the answer key. (I hope this has its own merits)\n",
    "# The answer key seems to hone in on the fact that there is a difference in means which is supported by what we found with our CIs not over lapping.\n",
    "# I am however too concerned over the r squared value to be able to pull the trigger on the idea that we have sufficient evidence to reject the null.\n",
    "# So most likely I have committed a type 2 error in failing to reject the null hypothesis when in fact I should have.\n",
    "# What do you think? We have strong evidence but can we actually go against what the r squared is telling us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}